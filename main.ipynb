{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import tf_text to load the ops used by the tokenizer saved model\n",
    "import tensorflow_text  # pylint: disable=unused-import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "logging.getLogger('tensorflow').setLevel(logging.ERROR) # suppress warnings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 15:21:51.589620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 15:21:51.707669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 15:21:51.707922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 15:21:51.709226: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-07 15:21:51.710181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 15:21:51.710501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 15:21:51.710755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 15:21:52.400169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 15:21:52.400301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 15:21:52.400394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 15:21:52.400484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1617 MB memory:  -> device: 0, name: NVIDIA GeForce MX250, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Yields pairs of text examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
      "mas e se estes fatores fossem ativos ?\n",
      "mas eles não tinham a curiosidade de me testar .\n",
      "\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 15:21:58.782633: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "  for pt in pt_examples.numpy():\n",
    "    print(pt.decode('utf-8'))\n",
    "\n",
    "  print()\n",
    "\n",
    "  for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'./ted_hrlr_translate_pt_en_converter.zip'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['HTTP_PROXY']='http://127.0.0.1:1080'\n",
    "os.environ['HTTPS_PROXY']='http://127.0.0.1:1080'\n",
    "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
    "tf.keras.utils.get_file(\n",
    "    f'{model_name}.zip',\n",
    "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['detokenize',\n 'get_reserved_tokens',\n 'get_vocab_path',\n 'get_vocab_size',\n 'lookup',\n 'tokenize',\n 'tokenizer',\n 'vocab']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The \"tokenize\" method converts a batch of strings to a padded-batch pf token IDs. This method splits punctuation, lowercases and unicodenormalizes the input before tokenizing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308, 74, 2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15, 3]\n",
      "[2, 87, 90, 107, 76, 129, 1852, 30, 3]\n",
      "[2, 87, 83, 149, 50, 9, 56, 664, 85, 2512, 15, 3]\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizers.en.tokenize(en_examples)\n",
    "\n",
    "for row in encoded.to_list():\n",
    "    print(row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Detokenize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n ' t test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "round_trip = tokenizers.en.detokenize(encoded)\n",
    "\n",
    "for line in round_trip.numpy():\n",
    "    print(line.decode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The lower level lookup method converts from token-IDs to token text\n",
    "Here you can see the subword aspect of the tokenizers. The word \"searchability\" is decomposed into \"search ##ability\" and the word \"serendipity\" into \"s ##ere ##nd ##ip ##ity\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[b'[START]', b'and', b'when', b'you', b'improve', b'search', b'##ability',\n  b',', b'you', b'actually', b'take', b'away', b'the', b'one', b'advantage',\n  b'of', b'print', b',', b'which', b'is', b's', b'##ere', b'##nd', b'##ip',\n  b'##ity', b'.', b'[END]']                                                 ,\n [b'[START]', b'but', b'what', b'if', b'it', b'were', b'active', b'?',\n  b'[END]']                                                           ,\n [b'[START]', b'but', b'they', b'did', b'n', b\"'\", b't', b'test', b'for',\n  b'curiosity', b'.', b'[END]']                                          ]>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizers.en.lookup(encoded)\n",
    "tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Investigate the distribution of tokens per example in the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................."
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "\n",
    "for pt_examples, en_examples in train_examples.batch(1024):\n",
    "    pt_tokens = tokenizers.pt.tokenize(pt_examples)\n",
    "    lengths.append(pt_tokens.row_lengths())\n",
    "\n",
    "    en_tokens = tokenizers.en.tokenize(en_examples)\n",
    "    lengths.append(en_tokens.row_lengths())\n",
    "    print('.', end='', flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Max tokens per example: 320')"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_lengths = np.concatenate(lengths)\n",
    "\n",
    "plt.hist(all_lengths, np.linspace(0, 500, 101))\n",
    "max_length = max(all_lengths)\n",
    "plt.plot([max_length, max_length], plt.ylim())\n",
    "plt.title(f'Max tokens per example: {max_length}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "MAX_TOKENS = 128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop the examples longer than MAX_TOKENS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def filter_max_tokens(pt, en):\n",
    "    num_tokens = tf.maximum(tf.shape(pt)[1], tf.shape(en)[1])\n",
    "    return num_tokens < MAX_TOKENS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "tokenize the batches of raw text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def tokenize_pairs(pt, en):\n",
    "    pt = tokenizers.pt.tokenize(pt)\n",
    "    # convert from ragged to dense, padding with zero\n",
    "    pt = pt.to_tensor()\n",
    "\n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    # convert from ragged to dense, padding with zero\n",
    "    en = en.to_tensor()\n",
    "\n",
    "    return pt, en"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "a simple input pipeline that processes, shuffles and batches the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def make_batches(ds):\n",
    "    return (\n",
    "        ds\n",
    "        .cache()\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .filter(filter_max_tokens)\n",
    "        .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "train_batches = make_batches(train_examples)\n",
    "val_batches = make_batches(val_examples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Positional encoding\n",
    "\n",
    "# HERE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2) / np.float32(d_model)))\n",
    "    return pos * angle_rates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 5\n",
    "(i//2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0],\n       [1],\n       [2],\n       [3],\n       [4]])"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(5)[:, np.newaxis]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 1, 2, 3, 4]])"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(5)[np.newaxis, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(np.newaxis)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "a = np.array([[0, 4], [0, 4]])\n",
    "b = np.sin(a[:, 1::2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.7568025],\n       [-0.7568025]])"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sfag\n"
     ]
    }
   ],
   "source": [
    "c = \"sdfsafg\"\n",
    "print(c[0::2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}